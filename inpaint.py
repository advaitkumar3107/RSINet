# -*- coding: utf-8 -*-
"""EdgeConnect_Official

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xkizorZA0Re_PgMXvUz1HKeP4oVFgsF9
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
#%matplotlib inline
import argparse
import os
import pickle
import glob
import random
import math
from random import randint
import scipy
from scipy.misc import imread
from PIL import Image
import torch
import torch.nn as nn
from torch.nn import init
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision
import torchvision.transforms.functional as F
import torch.nn.functional as TF
from torchvision import models
import torchvision.datasets as dset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torch.autograd import Variable
import numpy as np
import matplotlib.pyplot as plt
import cv2
from skimage.feature import canny
from skimage.color import rgb2gray, gray2rgb

from dataset import *
from utilities import *
from metrics import *
from models import *

os.environ['CUDA_VISIBLE_DEVICES'] = '1'

torch.cuda.empty_cache()
torch.cuda.set_device(0)

device = 'cuda'
torch.cuda.manual_seed(7)
torch.manual_seed(7)
np.random.seed(7)
torch.cuda.empty_cache()

CUDA_LAUNCH_BLOCKING = 1

train_dataset = dset.ImageFolder('AerialPhoto_split/train')
val_dataset = dset.ImageFolder('AerialPhoto_split/val')

train_loader = torch.utils.data.DataLoader(Dataset(train_dataset), batch_size = 4, shuffle = True)
val_loader = torch.utils.data.DataLoader(Dataset(val_dataset, augment = True, training = False), batch_size = 4, shuffle = False)

def train_inpainting(edge_generator, inpaint_generator, inpaint_discriminator, vgg19, train_loader, epoch, num_epochs, l1_loss, adversarial_loss, inpaint_gen_optimizer, inpaint_dis_optimizer, inpaint_loss):
      ### inpaint discriminator loss ###
  edge_generator.eval()
  inpaint_generator.train()
  inpaint_discriminator.train()

  for i,items in enumerate(train_loader):
    inpaint_gen_optimizer.zero_grad()
    inpaint_dis_optimizer.zero_grad()

    images, images_gray, edges, masks = items
    images, images_gray, edges, masks = images.cuda(), images_gray.cuda(), edges.cuda(), masks.cuda()

    edges_masked = edges * (1 - masks)
    images_gray_masked = images_gray * (1 - masks) + masks
    inputs = torch.cat((images_gray_masked, edges_masked, masks), dim = 1)
    e_outputs = edge_generator(inputs)

    e_outputs = e_outputs * masks + edges * (1 - masks)

    images_masked = images * (1 - masks) + masks

    inputs = torch.cat((images_masked, e_outputs), dim = 1)

  #  inputs = images_masked
    outputs = inpaint_generator(inputs)
  
    i_gen_loss = 0
    i_dis_loss = 0

    i_dis_input_real = images
    i_dis_input_fake = outputs.detach()
    i_dis_real, _ = inpaint_discriminator(i_dis_input_real)
    i_dis_fake, _ = inpaint_discriminator(i_dis_input_fake)

    target_real_label = 1.0
    target_fake_label = 0.0
    real_label = torch.tensor(target_real_label)
    fake_label = torch.tensor(target_fake_label)

    i_dis_labels = real_label.expand_as(i_dis_real)
    i_dis_real_loss = adversarial_loss(i_dis_real, i_dis_labels.cuda())
    
    i_labels = fake_label.expand_as(i_dis_fake)
    i_dis_fake_loss = adversarial_loss(i_dis_fake, i_labels.cuda())

    i_dis_loss += (i_dis_real_loss + i_dis_fake_loss) / 2



    ### inpaint generator adversarial loss ###
    i_gen_input_fake = outputs
    i_gen_fake, _ = inpaint_discriminator(i_gen_input_fake)

    i_gen_labels = real_label.expand_as(i_gen_fake)
    i_gen_gan_loss = adversarial_loss(i_gen_fake, i_gen_labels.cuda()) * 0.1
    i_gen_loss += i_gen_gan_loss


    ### inpaint generator l1 loss ###
    i_gen_l1_loss = l1_loss(images, outputs) / torch.mean(masks)
    i_gen_loss += i_gen_l1_loss



    ### inpaint generator perceptual loss ###
    x_p_vgg, y_p_vgg = vgg19(outputs), vgg19(images)

    content_loss = 0.0
    content_loss += l1_loss(x_p_vgg['relu1_1'], y_p_vgg['relu1_1'])
    content_loss += l1_loss(x_p_vgg['relu2_1'], y_p_vgg['relu2_1'])
    content_loss += l1_loss(x_p_vgg['relu3_1'], y_p_vgg['relu3_1'])
    content_loss += l1_loss(x_p_vgg['relu4_1'], y_p_vgg['relu4_1'])
    content_loss += l1_loss(x_p_vgg['relu5_1'], y_p_vgg['relu5_1'])

    content_loss = content_loss * 0.1
    i_gen_loss += content_loss 


    ### inpaint generator style loss ###
    x_vgg, y_vgg = vgg19(outputs * masks), vgg19(images * masks)

    # Compute loss
    style_loss = 0.0
    style_loss += l1_loss(compute_gram(x_vgg['relu2_2']), compute_gram(y_vgg['relu2_2']))
    style_loss += l1_loss(compute_gram(x_vgg['relu3_4']), compute_gram(y_vgg['relu3_4']))
    style_loss += l1_loss(compute_gram(x_vgg['relu4_4']), compute_gram(y_vgg['relu4_4']))
    style_loss += l1_loss(compute_gram(x_vgg['relu5_2']), compute_gram(y_vgg['relu5_2']))

    style_loss = style_loss * 250
    i_gen_loss += style_loss 

    inpaint_loss.append(i_gen_loss)

    i_gen_loss.backward()
    inpaint_gen_optimizer.step()

    i_dis_loss.backward()
    inpaint_dis_optimizer.step()

    print('Epoch : %d/%d \t  Iters : %d  \t Inpaint Generator Loss : %.4f \t Inpaint discriminator loss : %.4f' % (epoch + 1, num_epochs, i , i_gen_loss, i_dis_loss))



def validation_inpaint(edge_generator, inpaint_generator, inpaint_discriminator, vgg19, val_loader, epoch, l1_loss, adversarial_loss, inpaint_val_loss):
  edge_generator.eval()
  inpaint_generator.eval()
  inpaint_discriminator.eval()
 
  global inpaint_best_loss
  inpaint_val_loss.append(0)
  
  for i,items in enumerate(val_loader):
    images, images_gray, edges, masks = items
    images, images_gray, edges, masks = images.cuda(), images_gray.cuda(), edges.cuda(), masks.cuda()
    
    edges_masked = edges * (1 - masks)
    images_gray_masked = images_gray * (1 - masks) + masks
    inputs = torch.cat((images_gray_masked, edges_masked, masks), dim = 1)
    e_outputs = edge_generator(inputs)

    e_outputs = e_outputs * masks + edges * (1 - masks)

    images_masked = images * (1 - masks) + masks

    inputs = torch.cat((images_masked, e_outputs), dim = 1)
   # inputs = images_masked
    outputs = inpaint_generator(inputs)

    i_gen_loss = 0

    target_real_label = 1.0
    target_fake_label = 0.0
    real_label = torch.tensor(target_real_label)
    fake_label = torch.tensor(target_fake_label)

    ### inpaint generator adversarial loss ###
    i_gen_input_fake = outputs
    i_gen_fake, _ = inpaint_discriminator(i_gen_input_fake)

    i_gen_labels = real_label.expand_as(i_gen_fake)
    i_gen_gan_loss = adversarial_loss(i_gen_fake, i_gen_labels.cuda()) * 0.1
    i_gen_loss += i_gen_gan_loss


    ### inpaint generator l1 loss ###
    i_gen_l1_loss = l1_loss(images, outputs) / torch.mean(masks)
    i_gen_loss += i_gen_l1_loss


    ### inpaint generator perceptual loss ###
    x_p_vgg, y_p_vgg = vgg19(outputs), vgg19(images)

    content_loss = 0.0
    content_loss += l1_loss(x_p_vgg['relu1_1'], y_p_vgg['relu1_1'])
    content_loss += l1_loss(x_p_vgg['relu2_1'], y_p_vgg['relu2_1'])
    content_loss += l1_loss(x_p_vgg['relu3_1'], y_p_vgg['relu3_1'])
    content_loss += l1_loss(x_p_vgg['relu4_1'], y_p_vgg['relu4_1'])
    content_loss += l1_loss(x_p_vgg['relu5_1'], y_p_vgg['relu5_1'])

    content_loss = content_loss * 0.1
    i_gen_loss += content_loss 


    ### inpaint generator style loss ###
    x_vgg, y_vgg = vgg19(outputs * masks), vgg19(images * masks)

    # Compute loss
    style_loss = 0.0
    style_loss += l1_loss(compute_gram(x_vgg['relu2_2']), compute_gram(y_vgg['relu2_2']))
    style_loss += l1_loss(compute_gram(x_vgg['relu3_4']), compute_gram(y_vgg['relu3_4']))
    style_loss += l1_loss(compute_gram(x_vgg['relu4_4']), compute_gram(y_vgg['relu4_4']))
    style_loss += l1_loss(compute_gram(x_vgg['relu5_2']), compute_gram(y_vgg['relu5_2']))

    style_loss = style_loss * 250
    i_gen_loss += style_loss 

    inpaint_val_loss[-1] = inpaint_val_loss[-1] + i_gen_loss.data
    print('Inpaint_Val_loss = %.4f' % (inpaint_val_loss[-1]/(i+1)))

  inpaint_val_loss[-1] = inpaint_val_loss[-1]/len(val_loader)

  if inpaint_best_loss > inpaint_val_loss[-1]:
    inpaint_best_loss = inpaint_val_loss[-1]
    print('Saving...')

    state = {'inpaint_generator' : inpaint_generator}
    torch.save(state, 'aerialphoto_rectangle_official_inpaint_best.ckpt.t7')
    
    f = open("inpaint_best_loss.txt", "w")
    f.write(str(inpaint_best_loss.item()))
    f.close()


inpaint_loss = []
inpaint_val_loss = []

torch.cuda.empty_cache()
vgg = VGG19().cuda()

checkpoints1 = torch.load('aerialphoto_rectangle_official_edge_load.ckpt.t7')
checkpoints2 = torch.load('aerialphoto_rectangle_official_inpaint_load.ckpt.t7')
edge_generator = checkpoints1['edge_generator']
inpaint_generator = checkpoints2['inpaint_generator']
inpaint_discriminator = checkpoints2['inpaint_discriminator']

#inpaint_generator = InpaintGenerator().cuda()
#inpaint_discriminator = Discriminator(3).cuda()

inpaint_gen_opt = optim.Adam(params = inpaint_generator.parameters(), lr = float(0.0001), betas = (0.0, 0.9))
inpaint_dis_opt = optim.Adam(params = inpaint_discriminator.parameters(), lr = float(0.00001), betas = (0.0, 0.9))

l1_loss = nn.L1Loss()
adversarial_loss = nn.BCELoss()

num_epochs = 3

h = open('inpaint_best_loss.txt','r')
inpaint_best_loss = float(h.read())
h.close()

#inpaint_best_loss = 1e5

for epoch in range(num_epochs):	
  train_inpainting(edge_generator, inpaint_generator, inpaint_discriminator, vgg, train_loader, epoch, num_epochs, l1_loss, adversarial_loss, inpaint_gen_opt, inpaint_dis_opt, inpaint_loss)
  validation_inpaint(edge_generator, inpaint_generator, inpaint_discriminator, vgg, val_loader, epoch, l1_loss, adversarial_loss, inpaint_val_loss)
        
  checkpoints = {'inpaint_generator' : inpaint_generator, 'inpaint_discriminator' : inpaint_discriminator}
  torch.save(checkpoints, 'aerialphoto_rectangle_official_inpaint_load.ckpt.t7')
  print('Epoch : %d/%d' % (epoch+1, num_epochs))